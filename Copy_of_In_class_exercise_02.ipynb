{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of In_class_exercise_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vyshnav23/vyshnav_INFO5731_Spring2020/blob/master/Copy_of_In_class_exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo5bsEh2eeWi",
        "colab_type": "text"
      },
      "source": [
        "# **The second In-class-exercise**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sPQ58dIeqgp",
        "colab_type": "text"
      },
      "source": [
        "(1) Write a Python program to find the duplicate elements in a given array of integers. Return -1 If there are no such elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnrvKMFTeoJR",
        "colab_type": "code",
        "outputId": "0cd821d1-2110-4c2f-85fa-04901752e73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def Repeat(x): \n",
        "    _size = len(x) \n",
        "    repeated = []\n",
        "    c=0 \n",
        "    for i in range(_size): \n",
        "        k = i + 1\n",
        "        for j in range(k, _size): \n",
        "            if x[i] == x[j] and x[i] not in repeated: \n",
        "                repeated.append(x[i])\n",
        "                c=c+1\n",
        "    if c>1:\n",
        "     return repeated \n",
        "    else: \n",
        "     return -1\n",
        "list1 = [10, 20,30, 40,  \n",
        "         50, 60, -20] \n",
        "print (Repeat(list1))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYrH6n6IhZoQ",
        "colab_type": "text"
      },
      "source": [
        "(2) Write a Python program to select all the Sundays of a specified year.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSfPLd23eLpX",
        "colab_type": "code",
        "outputId": "56fccb86-a9f3-4d8c-ede4-a42e2a85ee7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "# write your answer here\n",
        "from datetime import date, timedelta\n",
        "\n",
        "def all_sundays(year):\n",
        "# January 1st of the given year\n",
        "       dt = date(year, 1, 1)\n",
        "# First Sunday of the given year       \n",
        "       dt += timedelta(days = 6 - dt.weekday())  \n",
        "       while dt.year == year:\n",
        "          yield dt\n",
        "          dt += timedelta(days = 7)\n",
        "          \n",
        "for s in all_sundays(2021):\n",
        "   print(s)\n",
        "   \n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-03\n",
            "2021-01-10\n",
            "2021-01-17\n",
            "2021-01-24\n",
            "2021-01-31\n",
            "2021-02-07\n",
            "2021-02-14\n",
            "2021-02-21\n",
            "2021-02-28\n",
            "2021-03-07\n",
            "2021-03-14\n",
            "2021-03-21\n",
            "2021-03-28\n",
            "2021-04-04\n",
            "2021-04-11\n",
            "2021-04-18\n",
            "2021-04-25\n",
            "2021-05-02\n",
            "2021-05-09\n",
            "2021-05-16\n",
            "2021-05-23\n",
            "2021-05-30\n",
            "2021-06-06\n",
            "2021-06-13\n",
            "2021-06-20\n",
            "2021-06-27\n",
            "2021-07-04\n",
            "2021-07-11\n",
            "2021-07-18\n",
            "2021-07-25\n",
            "2021-08-01\n",
            "2021-08-08\n",
            "2021-08-15\n",
            "2021-08-22\n",
            "2021-08-29\n",
            "2021-09-05\n",
            "2021-09-12\n",
            "2021-09-19\n",
            "2021-09-26\n",
            "2021-10-03\n",
            "2021-10-10\n",
            "2021-10-17\n",
            "2021-10-24\n",
            "2021-10-31\n",
            "2021-11-07\n",
            "2021-11-14\n",
            "2021-11-21\n",
            "2021-11-28\n",
            "2021-12-05\n",
            "2021-12-12\n",
            "2021-12-19\n",
            "2021-12-26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIpziZ6Sjie-",
        "colab_type": "text"
      },
      "source": [
        "(3) Python files reading and writing. Download the “[exercise_02_data _collection.zip](https://github.com/unt-iialab/INFO5731_Spring2020/blob/master/In_class_exercise/exercise_02_data_collection.zip)” to your local and un-zip it.\n",
        "\n",
        "*   Write a program to read all the txt files and save the sentences in all the files into one csv file with two columns, the first column is sentence id (txt file name+sentence line number), the second column is the sentence text content.\n",
        "*   Remove all the punctuations from the sentences, save the processed sentences into a new column in the same csv file.\n",
        "*   Ask the user to enter a word, return all the sentences that include this word, three kinds of information should be returned: sentence id, sentence text content, the count that user input word appear in the sentence..\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3CUsrWOj1Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write your answer here\n",
        "import os,csv\n",
        "path = './'\n",
        "for r,d,f in os.walk(path):\n",
        "     for file in f:\n",
        "             if '.txt' in file:\n",
        "                with open('test.csv','w',newline='') as fp:\n",
        "                    a = csv.writer(fp,delimiter=',')\n",
        "                    a.writerow(f\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-12cqmJEpZOh",
        "colab_type": "text"
      },
      "source": [
        "(4) Install packages nltk, numpy, scipy, pandas, and sklearn on Google Colab. Write a program to test whether they are installed successfully. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1pn1Zl2qK77",
        "colab_type": "code",
        "outputId": "5b82c4c9-3c79-4e02-8c44-a59c5e2976f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "!pip install nltk\n",
        "!pip install numpy\n",
        "!pip install scipy\n",
        "!pip install pandas\n",
        "!pip install sklearn\n",
        "from scipy import linalg\n",
        "import numpy as np\n",
        "#define two dimensional array\n",
        "arr = np.array([[5,4],[6,3]])\n",
        "#pass value into function\n",
        "eg_val, eg_vect = linalg.eig(arr)\n",
        "#get eigenvalues\n",
        "print(eg_val)\n",
        "#get eigenvectors\n",
        "print(eg_vect)\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'X':[78,85,96,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]});\n",
        "print(df)\n",
        "import nltk.corpus\n",
        "dir(nltk.corpus)\n",
        "print(\"\\nAvailable corpus names:\")\n",
        "print(dir(nltk.corpus))\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.17.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.17.5)\n",
            "[ 9.+0.j -1.+0.j]\n",
            "[[ 0.70710678 -0.5547002 ]\n",
            " [ 0.70710678  0.83205029]]\n",
            "    X   Y   Z\n",
            "0  78  84  86\n",
            "1  85  94  97\n",
            "2  96  89  96\n",
            "3  80  83  72\n",
            "4  86  86  83\n",
            "\n",
            "Available corpus names:\n",
            "['AlignedCorpusReader', 'AlpinoCorpusReader', 'BNCCorpusReader', 'BracketParseCorpusReader', 'CHILDESCorpusReader', 'CMUDictCorpusReader', 'CategorizedBracketParseCorpusReader', 'CategorizedCorpusReader', 'CategorizedPlaintextCorpusReader', 'CategorizedSentencesCorpusReader', 'CategorizedTaggedCorpusReader', 'ChasenCorpusReader', 'ChunkedCorpusReader', 'ComparativeSentencesCorpusReader', 'ConllChunkCorpusReader', 'ConllCorpusReader', 'CorpusReader', 'CrubadanCorpusReader', 'DependencyCorpusReader', 'EuroparlCorpusReader', 'FramenetCorpusReader', 'IEERCorpusReader', 'IPIPANCorpusReader', 'IndianCorpusReader', 'KNBCorpusReader', 'LazyCorpusLoader', 'LinThesaurusCorpusReader', 'MTECorpusReader', 'MWAPPDBCorpusReader', 'MacMorphoCorpusReader', 'NKJPCorpusReader', 'NPSChatCorpusReader', 'NombankCorpusReader', 'NonbreakingPrefixesCorpusReader', 'OpinionLexiconCorpusReader', 'PPAttachmentCorpusReader', 'PanLexLiteCorpusReader', 'Pl196xCorpusReader', 'PlaintextCorpusReader', 'PortugueseCategorizedPlaintextCorpusReader', 'PropbankCorpusReader', 'ProsConsCorpusReader', 'RTECorpusReader', 'RegexpTokenizer', 'ReviewsCorpusReader', 'SemcorCorpusReader', 'SensevalCorpusReader', 'SentiSynset', 'SentiWordNetCorpusReader', 'SinicaTreebankCorpusReader', 'StringCategoryCorpusReader', 'SwadeshCorpusReader', 'SwitchboardCorpusReader', 'SyntaxCorpusReader', 'TEICorpusView', 'TaggedCorpusReader', 'TimitCorpusReader', 'TimitTaggedCorpusReader', 'ToolboxCorpusReader', 'TwitterCorpusReader', 'UdhrCorpusReader', 'UnicharsCorpusReader', 'VerbnetCorpusReader', 'WordListCorpusReader', 'WordNetCorpusReader', 'WordNetICCorpusReader', 'XMLCorpusReader', 'YCOECorpusReader', '_LazyModule__lazymodule_globals', '_LazyModule__lazymodule_import', '_LazyModule__lazymodule_init', '_LazyModule__lazymodule_loaded', '_LazyModule__lazymodule_locals', '_LazyModule__lazymodule_name', '__builtins__', '__cached__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__file__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__lazymodule_loaded', '__le__', '__loader__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__package__', '__path__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__spec__', '__str__', '__subclasshook__', '__weakref__', 'abc', 'alpino', 'brown', 'cess_cat', 'cess_esp', 'cmudict', 'comparative_sentences', 'comtrans', 'conll2000', 'conll2002', 'conll2007', 'crubadan', 'demo', 'dependency_treebank', 'find_corpus_fileids', 'floresta', 'framenet', 'framenet15', 'gazetteers', 'genesis', 'gutenberg', 'ieer', 'inaugural', 'indian', 'jeita', 'knbc', 'lin_thesaurus', 'mac_morpho', 'machado', 'masc_tagged', 'movie_reviews', 'multext_east', 'names', 'nombank', 'nombank_ptb', 'nonbreaking_prefixes', 'nps_chat', 'opinion_lexicon', 'perluniprops', 'ppattach', 'product_reviews_1', 'product_reviews_2', 'propbank', 'propbank_ptb', 'pros_cons', 'ptb', 'qc', 're', 'reader', 'reuters', 'rte', 'semcor', 'senseval', 'sentence_polarity', 'sentiwordnet', 'shakespeare', 'sinica_treebank', 'state_union', 'stopwords', 'subjectivity', 'swadesh', 'swadesh110', 'swadesh207', 'switchboard', 'tagged_treebank_para_block_reader', 'teardown_module', 'timit', 'timit_tagged', 'toolbox', 'treebank', 'treebank_chunk', 'treebank_raw', 'twitter_samples', 'udhr', 'udhr2', 'universal_treebanks', 'util', 'verbnet', 'webtext', 'wordnet', 'wordnet_ic', 'words']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}