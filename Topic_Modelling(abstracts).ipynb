{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modelling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vyshnav23/vyshnav_INFO5731_Spring2020/blob/master/Topic_Modelling(abstracts).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUZrtp6KB50B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Nm7Sz2CQXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df1 = pd.read_csv('Final_Table_1.csv')\n",
        "df3 = pd.read_csv('Final_Table_1.csv',low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEXiyyZeFcXt",
        "colab_type": "code",
        "outputId": "7268a803-cf7c-4aae-a425-81826c2e13b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "df3.columns   "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Article_id', 'Venue', 'Title', 'Year', 'Abstract', 'Doi',\n",
              "       'fieldsOfStudy', 'topics', 'Downloadurl', 'TotalCitationCount',\n",
              "       'TotalDownloadCount', 'Influentialcitationcount'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0IMaZcNCYwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3_title = df3['Abstract']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgq7N1eyCejt",
        "colab_type": "code",
        "outputId": "2a861523-0aac-48bb-87ed-7fc22c591774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df3_title.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4433,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr9h-r7MVcie",
        "colab_type": "code",
        "outputId": "6704e4ab-c811-4ec1-9e84-39a681721dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim import corpora, models\n",
        "import gensim\n",
        "nltk.download('stopwords')\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# create English stop words list\n",
        "en_stop = stopwords.words('english')\n",
        "\n",
        "# Create p_stemmer of class PorterStemmer\n",
        "p_stemmer = PorterStemmer()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwrp91vgIPPp",
        "colab_type": "code",
        "outputId": "3b2b6ba1-b200-487f-b6a3-d79dff7ba4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "title_doc = []\n",
        "abstract_doc = []\n",
        "for i in range(1971,2017,5):\n",
        "  print()\n",
        "  title_df = df3.loc[(df3['Year'] >=i) & (df3['Year']<i+5),'Title']\n",
        "  abstract_df = df3.loc[(df3['Year'] >=i) & (df3['Year']<i+5),'Abstract']\n",
        "\n",
        "  title_list = title_df.tolist()\n",
        "  title = ''.join(title_list)\n",
        "  title_doc.append(title)\n",
        "\n",
        "  abstract_list = abstract_df.tolist()\n",
        "  abstract = ''.join(abstract_list)\n",
        "  abstract_doc.append(abstract)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oea7Kjv9ZPjD",
        "colab_type": "code",
        "outputId": "b5608f3c-902f-4226-e8d4-0cd693f3fb21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print(len(title_doc[i]), len(abstract_doc[i]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1162 12267\n",
            "1587 13907\n",
            "5052 50101\n",
            "11063 99347\n",
            "10057 97149\n",
            "22559 224146\n",
            "35011 363527\n",
            "59288 672796\n",
            "69987 926135\n",
            "67101 864081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FmgTOWeZGb2",
        "colab_type": "code",
        "outputId": "9371140e-7411-4fbf-8e25-79c4f6c26988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# Extracting Keywords from titles\n",
        "for i in range(len(title_doc)):\n",
        "    \n",
        "    \n",
        "    # clean and tokenize document string\n",
        "    raw_title = title_doc[i].lower()\n",
        "    title_tokens = tokenizer.tokenize(raw_title)\n",
        "\n",
        "\n",
        "    # remove stop words from tokens\n",
        "    stopped_title_tokens = [i for i in title_tokens if not i in en_stop]\n",
        "    \n",
        "    # stem tokens\n",
        "    # stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
        "    title_texts = []\n",
        "    # add tokens to list\n",
        "    title_texts.append(stopped_title_tokens)\n",
        "\n",
        "    # turn our tokenized documents into a id <-> term dictionary\n",
        "    title_dictionary = corpora.Dictionary(title_texts)\n",
        "\n",
        "        \n",
        "    # convert tokenized documents into a document-term matrix\n",
        "    title_corpus = [title_dictionary.doc2bow(title) for title in title_texts]\n",
        "\n",
        "    # generate LDA model\n",
        "    title_ldamodel = gensim.models.ldamodel.LdaModel(title_corpus, num_topics=1,id2word = title_dictionary, passes=20)\n",
        "    \n",
        "    # lda_pred.append(title_ldamodel.print_topics())\n",
        "    print(title_ldamodel.print_topics(num_words = 4))\n",
        "    print()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.025*\"retrieval\" + 0.025*\"data\" + 0.025*\"file\" + 0.020*\"storage\"')]\n",
            "\n",
            "[(0, '0.041*\"retrieval\" + 0.033*\"information\" + 0.021*\"document\" + 0.021*\"based\"')]\n",
            "\n",
            "[(0, '0.036*\"information\" + 0.034*\"retrieval\" + 0.018*\"document\" + 0.013*\"user\"')]\n",
            "\n",
            "[(0, '0.037*\"information\" + 0.035*\"retrieval\" + 0.016*\"document\" + 0.014*\"based\"')]\n",
            "\n",
            "[(0, '0.027*\"information\" + 0.026*\"retrieval\" + 0.017*\"text\" + 0.013*\"based\"')]\n",
            "\n",
            "[(0, '0.027*\"retrieval\" + 0.026*\"information\" + 0.019*\"poster\" + 0.015*\"abstract\"')]\n",
            "\n",
            "[(0, '0.019*\"information\" + 0.016*\"retrieval\" + 0.014*\"based\" + 0.013*\"using\"')]\n",
            "\n",
            "[(0, '0.014*\"based\" + 0.013*\"information\" + 0.013*\"search\" + 0.012*\"retrieval\"')]\n",
            "\n",
            "[(0, '0.021*\"search\" + 0.014*\"based\" + 0.013*\"information\" + 0.010*\"web\"')]\n",
            "\n",
            "[(0, '0.013*\"search\" + 0.012*\"information\" + 0.010*\"retrieval\" + 0.010*\"based\"')]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJezULrCd1wE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "ce6d46b3-6070-4703-e8c0-33dd5c4b09bb"
      },
      "source": [
        "# Extracting Keywords from Abstracts\n",
        "for i in range(len(abstract_doc)):\n",
        "    \n",
        "    \n",
        "    # clean and tokenize document string\n",
        "    raw_abstract = abstract_doc[i].lower()\n",
        "    abstract_tokens = tokenizer.tokenize(raw_abstract)\n",
        "\n",
        "\n",
        "    # remove stop words from tokens\n",
        "    stopped_abstract_tokens = [i for i in abstract_tokens if not i in en_stop]\n",
        "    \n",
        "    # stem tokens\n",
        "    # stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
        "    abstract_texts = []\n",
        "    # add tokens to list\n",
        "    abstract_texts.append(stopped_abstract_tokens)\n",
        "\n",
        "    # turn our tokenized documents into a id <-> term dictionary\n",
        "    abstract_dictionary = corpora.Dictionary(abstract_texts)\n",
        "\n",
        "        \n",
        "    # convert tokenized documents into a document-term matrix\n",
        "    abstract_corpus = [abstract_dictionary.doc2bow(abstract) for abstract in abstract_texts]\n",
        "\n",
        "    # generate LDA model\n",
        "    abstract_ldamodel = gensim.models.ldamodel.LdaModel(abstract_corpus, num_topics=1,id2word = abstract_dictionary, passes=20)\n",
        "    \n",
        "    # lda_pred.append(title_ldamodel.print_topics())\n",
        "    print(abstract_ldamodel.print_topics(num_words = 4))\n",
        "    print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.012*\"system\" + 0.010*\"data\" + 0.009*\"retrieval\" + 0.008*\"information\"')]\n",
            "\n",
            "[(0, '0.027*\"e\" + 0.019*\"retrieval\" + 0.012*\"r\" + 0.010*\"system\"')]\n",
            "\n",
            "[(0, '0.015*\"retrieval\" + 0.012*\"system\" + 0.010*\"information\" + 0.008*\"systems\"')]\n",
            "\n",
            "[(0, '0.017*\"retrieval\" + 0.012*\"information\" + 0.008*\"system\" + 0.007*\"document\"')]\n",
            "\n",
            "[(0, '0.017*\"retrieval\" + 0.010*\"information\" + 0.007*\"documents\" + 0.007*\"text\"')]\n",
            "\n",
            "[(0, '0.012*\"retrieval\" + 0.011*\"information\" + 0.009*\"documents\" + 0.007*\"query\"')]\n",
            "\n",
            "[(0, '0.012*\"retrieval\" + 0.009*\"information\" + 0.007*\"search\" + 0.007*\"documents\"')]\n",
            "\n",
            "[(0, '0.011*\"search\" + 0.010*\"retrieval\" + 0.009*\"information\" + 0.009*\"query\"')]\n",
            "\n",
            "[(0, '0.014*\"search\" + 0.009*\"information\" + 0.008*\"query\" + 0.007*\"user\"')]\n",
            "\n",
            "[(0, '0.011*\"search\" + 0.008*\"information\" + 0.007*\"users\" + 0.007*\"user\"')]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijHGHhTQvHjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}